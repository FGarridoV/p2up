{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'uemb' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/francisco/.pyenv/versions/3.11.5/envs/uemb/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from tools.trainer import PlaceEmbeddingTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 40\n",
    "memory_batch_size = 8\n",
    "num_epochs = 3\n",
    "img_transform = 'default'\n",
    "base_model = 'resnet18'    \n",
    "pooling = 'mean'\n",
    "encoder_layers = [512]\n",
    "projection_layers = [256]\n",
    "use_dropout = True\n",
    "dropout_rate = 0.3\n",
    "loss_dist = 'euclidean'\n",
    "loss_margin = 0.2\n",
    "loss_swap = True\n",
    "lr = 0.001\n",
    "adjust_lr = False\n",
    "weight_decay = 0.001\n",
    "backward_freq = 'batch' # 'mbatch' or 'batch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep fixed\n",
    "seed = 46  \n",
    "data_splits = {'train': 0.8, \n",
    "               'val': 0.1, \n",
    "               'test': 0.1}\n",
    "base_pretrained = True\n",
    "loss_kind = 'triplet'\n",
    "count_corrects = True \n",
    "\n",
    "optimizer = 'adam'\n",
    "lr = 0.001\n",
    "adjust_lr = False\n",
    "weight_decay = 0.001\n",
    "backward_freq = 'batch' # 'mbatch' or 'batch'\n",
    "verbose = True              # Print the progress\n",
    "gpu = True                  # Try to use GPU\n",
    "use_tensorboard = True      # Use tensorboard for logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "| PLACE EMBEDDING TRAINER: 20240319_121016 |\n",
      "--------------------------------------------\n",
      "Working on device: mps\n",
      "Using tensorboard: True\n",
      "\n",
      "Dataset:\n",
      "    Total triplets: 510\n",
      "    Training set size: 408 triplets (80.000%)\n",
      "    Validation set size: 51 triplets (10.000%)\n",
      "    Reserved for testing: 51 triplets (10.000%)\n",
      "    Batch size: 40 (looping on 5 memory batches - 8 instances)\n",
      "\n",
      "{'img_transform': 'default', 'train_split': 408, 'val_split': 51, 'test_split': 51, 'data_seed': 21}\n",
      "Model:\n",
      "    Name: model_resnet18p_mean_enc_512_proj_256_d03\n",
      "    Image embedding model: resnet18 -> 512 D embedding space\n",
      "    Image emb. pretrained: True\n",
      "    Pooling rule: mean -> 512 D embedding space\n",
      "    Encoder layers: 512 -> [512]\n",
      "    Projection layers: 512 -> [256]\n",
      "    Dropout rate: 0.3\n",
      "    Number of parameters: 11,570,496\n",
      "\n",
      "Loss function:\n",
      "    Kind: triplet loss\n",
      "    Distance metric: euclidean\n",
      "    Margin: 0.2\n",
      "    Swap: True\n",
      "    Reduction: sum\n",
      "    Count corrects: True\n",
      "\n",
      "Optimizer:\n",
      "    Name: adam\n",
      "    Learning rate: 0.001\n",
      "    Weight decay: 0.001\n",
      "    Backpropagation frequency: batch\n",
      "    Learning rate scheduler: False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New trainer\n",
    "trainer = PlaceEmbeddingTrainer(name = None,\n",
    "                                use_gpu = gpu,\n",
    "                                use_tensorboard = use_tensorboard, \n",
    "                                verbose = verbose)\n",
    "\n",
    "# Set the data\n",
    "trainer.set_data(triplets_path = 'data/triplets.csv',\n",
    "                 img_transform = img_transform, \n",
    "                 data_splits = data_splits, \n",
    "                 batch_size = batch_size, \n",
    "                 memory_batch_size = memory_batch_size)\n",
    "\n",
    "print(trainer.trainer_dict)\n",
    "\n",
    "# Define the model\n",
    "trainer.set_model(base_model = base_model, base_pretrained = base_pretrained, pooling = pooling, \n",
    "                  encoder_layers = encoder_layers, projection_layers = projection_layers,\n",
    "                  use_dropout = use_dropout, dropout_rate = dropout_rate)\n",
    "\n",
    "# Define the loss\n",
    "trainer.set_loss(loss_kind = loss_kind, loss_dist = loss_dist, loss_margin = loss_margin, \n",
    "                 loss_swap = loss_swap, count_corrects = count_corrects)\n",
    "\n",
    "# Define the optimizer\n",
    "trainer.set_optimizer(optimizer = optimizer, learning_rate = lr, adjust_lr = adjust_lr, weight_decay = weight_decay, backward_freq = backward_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL TRAINING: 3 epochs | 11 batches\n",
      "---------------------------------------------\n",
      "\n",
      "EPOCH 1\n",
      "[12:10:16 19/03/2024] Epoch 1 - lr: 0.001000\n",
      "[12:10:23 19/03/2024]   Batch 1 - Loss: 0.458 - Accuracy: 25.000% (40)\n",
      "[12:10:58 19/03/2024]   Batch 2 - Loss: 0.665 - Accuracy: 40.000% (40)\n",
      "[12:11:25 19/03/2024]   Batch 3 - Loss: 0.410 - Accuracy: 40.000% (40)\n",
      "[12:11:58 19/03/2024]   Batch 4 - Loss: 0.434 - Accuracy: 47.500% (40)\n",
      "[12:12:29 19/03/2024]   Batch 5 - Loss: 0.458 - Accuracy: 32.500% (40)\n",
      "[12:12:59 19/03/2024]   Batch 6 - Loss: 0.619 - Accuracy: 40.000% (40)\n",
      "[12:13:23 19/03/2024]   Batch 7 - Loss: 0.659 - Accuracy: 32.500% (40)\n",
      "[12:13:44 19/03/2024]   Batch 8 - Loss: 0.537 - Accuracy: 45.000% (40)\n",
      "[12:14:09 19/03/2024]   Batch 9 - Loss: 0.444 - Accuracy: 37.500% (40)\n",
      "[12:14:32 19/03/2024]   Batch 10 - Loss: 0.518 - Accuracy: 45.000% (40)\n",
      "[12:14:50 19/03/2024]   Batch 11 - Loss: 0.751 - Accuracy: 25.000% (8)\n",
      "[12:14:51 19/03/2024] Epoch 1 - Train Loss: 0.525 - Train Accuracy: 38.235%\n",
      "[12:14:58 19/03/2024] Epoch 1 - Validation Loss: 0.200 - Validation Accuracy: 66.667%\n",
      "[12:14:59 19/03/2024] New best model stored at epoch 1 - val_loss: 0.200 - val_acc: 66.667% - elapsed_time: 282.272 seconds\n",
      "Epoch 1 Finished in 4.710 minutes\n",
      "Total time: 4.71 minutes\n",
      "\n",
      "EPOCH 2\n",
      "[12:14:59 19/03/2024] Epoch 2 - lr: 0.001000\n",
      "[12:15:18 19/03/2024]   Batch 1 - Loss: 0.329 - Accuracy: 47.500% (40)\n",
      "[12:15:52 19/03/2024]   Batch 2 - Loss: 0.513 - Accuracy: 47.500% (40)\n",
      "[12:16:21 19/03/2024]   Batch 3 - Loss: 0.411 - Accuracy: 47.500% (40)\n",
      "[12:16:51 19/03/2024]   Batch 4 - Loss: 0.434 - Accuracy: 45.000% (40)\n",
      "[12:17:20 19/03/2024]   Batch 5 - Loss: 0.456 - Accuracy: 37.500% (40)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train(num_epochs = num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip2up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
